{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"},{"sourceId":2280,"sourceType":"datasetVersion","datasetId":1272},{"sourceId":242592,"sourceType":"datasetVersion","datasetId":102285},{"sourceId":2598787,"sourceType":"datasetVersion","datasetId":1573501},{"sourceId":7520260,"sourceType":"datasetVersion","datasetId":4380745},{"sourceId":9792750,"sourceType":"datasetVersion","datasetId":6000807},{"sourceId":10566800,"sourceType":"datasetVersion","datasetId":6538660},{"sourceId":10590047,"sourceType":"datasetVersion","datasetId":6554101},{"sourceId":10606838,"sourceType":"datasetVersion","datasetId":6565987},{"sourceId":10614391,"sourceType":"datasetVersion","datasetId":6571374},{"sourceId":10640830,"sourceType":"datasetVersion","datasetId":6588252},{"sourceId":10641399,"sourceType":"datasetVersion","datasetId":6588676},{"sourceId":10647359,"sourceType":"datasetVersion","datasetId":6592543},{"sourceId":10718611,"sourceType":"datasetVersion","datasetId":6643896},{"sourceId":10719245,"sourceType":"datasetVersion","datasetId":6644397}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\n\n# Path to the directory in the dataset\ndataset_dir = '/kaggle/input/my45kstable/stable_signature main'\n\n# Destination working directory\nworking_dir = '/kaggle/working/'\n\n# Create the destination directory if it doesn't exist\nif not os.path.exists(working_dir):\n    os.makedirs(working_dir)\n\n# Function to copy files and directories recursively\ndef copy_tree(src, dst):\n    for item in os.listdir(src):\n        src_path = os.path.join(src, item)\n        dst_path = os.path.join(dst, item)\n        if os.path.isdir(src_path):\n            if not os.path.exists(dst_path):\n                os.makedirs(dst_path)\n            copy_tree(src_path, dst_path)\n        else:\n            shutil.copy2(src_path, dst_path)\n\n# Copy all items from dataset directory to working directory\ncopy_tree(dataset_dir, working_dir)\n\nprint(f\"All items copied to {working_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T05:26:49.261464Z","iopub.execute_input":"2025-02-11T05:26:49.261744Z","iopub.status.idle":"2025-02-11T05:26:51.494322Z","shell.execute_reply.started":"2025-02-11T05:26:49.261720Z","shell.execute_reply":"2025-02-11T05:26:51.493373Z"}},"outputs":[{"name":"stdout","text":"All items copied to /kaggle/working/\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T05:32:37.497654Z","iopub.execute_input":"2025-02-11T05:32:37.497983Z","iopub.status.idle":"2025-02-11T05:32:40.834317Z","shell.execute_reply.started":"2025-02-11T05:32:37.497949Z","shell.execute_reply":"2025-02-11T05:32:40.833322Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: omegaconf==2.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.1.1)\nRequirement already satisfied: einops==0.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.3.0)\nRequirement already satisfied: transformers==4.19.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.19.2)\nRequirement already satisfied: open_clip_torch==2.0.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\nRequirement already satisfied: torchmetrics==0.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.6.0)\nRequirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.10.1)\nRequirement already satisfied: augly==1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.0.0)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.24.0)\nRequirement already satisfied: pytorch-fid==0.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.3.0)\nRequirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.5.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (3.7.5)\nRequirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.1.1->-r requirements.txt (line 1)) (4.8)\nRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.1.1->-r requirements.txt (line 1)) (6.0.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (24.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (2.32.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (0.12.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (4.67.1)\nRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch==2.0.2->-r requirements.txt (line 4)) (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open_clip_torch==2.0.2->-r requirements.txt (line 4)) (0.20.1+cu121)\nRequirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from open_clip_torch==2.0.2->-r requirements.txt (line 4)) (6.3.1)\nRequirement already satisfied: iopath>=0.1.8 in /usr/local/lib/python3.10/dist-packages (from augly==1.0.0->-r requirements.txt (line 7)) (0.1.10)\nRequirement already satisfied: python-magic>=0.4.22 in /usr/local/lib/python3.10/dist-packages (from augly==1.0.0->-r requirements.txt (line 7)) (0.4.27)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pytorch-fid==0.3.0->-r requirements.txt (line 9)) (11.0.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->-r requirements.txt (line 10)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->-r requirements.txt (line 10)) (2024.2)\nRequirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 8)) (3.4.2)\nRequirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 8)) (2.36.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 8)) (2024.12.12)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 8)) (0.4)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 11)) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 11)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 11)) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 11)) (1.4.7)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 11)) (3.2.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.2->-r requirements.txt (line 3)) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.2->-r requirements.txt (line 3)) (4.12.2)\nRequirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.8->augly==1.0.0->-r requirements.txt (line 7)) (3.1.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.19.2->-r requirements.txt (line 3)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.19.2->-r requirements.txt (line 3)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.19.2->-r requirements.txt (line 3)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.19.2->-r requirements.txt (line 3)) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.19.2->-r requirements.txt (line 3)) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.19.2->-r requirements.txt (line 3)) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3->-r requirements.txt (line 10)) (1.17.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->open_clip_torch==2.0.2->-r requirements.txt (line 4)) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->open_clip_torch==2.0.2->-r requirements.txt (line 4)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9->open_clip_torch==2.0.2->-r requirements.txt (line 4)) (1.3.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch==2.0.2->-r requirements.txt (line 4)) (0.2.13)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.2->-r requirements.txt (line 3)) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.2->-r requirements.txt (line 3)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.2->-r requirements.txt (line 3)) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.2->-r requirements.txt (line 3)) (2024.12.14)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->open_clip_torch==2.0.2->-r requirements.txt (line 4)) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.19.2->-r requirements.txt (line 3)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.19.2->-r requirements.txt (line 3)) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.19.2->-r requirements.txt (line 3)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.19.2->-r requirements.txt (line 3)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers==4.19.2->-r requirements.txt (line 3)) (2024.2.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!apt-get update\n!apt-get install -y libmagic1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T05:32:44.588763Z","iopub.execute_input":"2025-02-11T05:32:44.589077Z","iopub.status.idle":"2025-02-11T05:32:50.602747Z","shell.execute_reply.started":"2025-02-11T05:32:44.589047Z","shell.execute_reply":"2025-02-11T05:32:50.601701Z"}},"outputs":[{"name":"stdout","text":"Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\nGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]                             \nGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]                \nGet:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]                                \nGet:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]                           \nGet:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]                           \nGet:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,311 kB]\nGet:9 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [66.7 kB]       \nGet:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]             \nGet:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,653 kB]\nGet:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,526 kB]\nGet:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\nGet:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,663 kB]                      \nGet:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,748 kB]          \nHit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease                        \nGet:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,911 kB]                \nGet:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\nGet:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,606 kB]\nGet:20 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [33.6 kB]\nGet:21 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [57.8 kB]\nGet:22 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,606 kB]           \nGet:23 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]\nGet:24 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [45.2 kB]\nFetched 28.9 MB in 2s (13.0 MB/s)                            \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nlibmagic1 is already the newest version (1:5.41-3ubuntu0.1).\nlibmagic1 set to manually installed.\n0 upgraded, 0 newly installed, 0 to remove and 124 not upgraded.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install pytorch-lightning==1.9.0\n!pip install xformers==0.0.28\n!pip install python-magic","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T05:32:53.444241Z","iopub.execute_input":"2025-02-11T05:32:53.444583Z"}},"outputs":[{"name":"stdout","text":"Collecting pytorch-lightning==1.9.0\n  Downloading pytorch_lightning-1.9.0-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (1.26.4)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (2.5.1+cu121)\nRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (4.67.1)\nRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (6.0.2)\nRequirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (2024.9.0)\nCollecting torchmetrics>=0.7.0 (from pytorch-lightning==1.9.0)\n  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (24.2)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (4.12.2)\nRequirement already satisfied: lightning-utilities>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (0.11.9)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (3.11.10)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.4.2->pytorch-lightning==1.9.0) (75.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.2->pytorch-lightning==1.9.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.2->pytorch-lightning==1.9.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.2->pytorch-lightning==1.9.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.2->pytorch-lightning==1.9.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.2->pytorch-lightning==1.9.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.2->pytorch-lightning==1.9.0) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.16.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->pytorch-lightning==1.9.0) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->pytorch-lightning==1.9.0) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.2->pytorch-lightning==1.9.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.2->pytorch-lightning==1.9.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.2->pytorch-lightning==1.9.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17.2->pytorch-lightning==1.9.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17.2->pytorch-lightning==1.9.0) (2024.2.0)\nRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (3.10)\nDownloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torchmetrics, pytorch-lightning\n  Attempting uninstall: torchmetrics\n    Found existing installation: torchmetrics 0.6.0\n    Uninstalling torchmetrics-0.6.0:\n      Successfully uninstalled torchmetrics-0.6.0\n  Attempting uninstall: pytorch-lightning\n    Found existing installation: pytorch-lightning 2.5.0.post0\n    Uninstalling pytorch-lightning-2.5.0.post0:\n      Successfully uninstalled pytorch-lightning-2.5.0.post0\nSuccessfully installed pytorch-lightning-1.9.0 torchmetrics-1.6.1\nCollecting xformers==0.0.28\n  Downloading xformers-0.0.28-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.28) (1.26.4)\nCollecting torch==2.4.1 (from xformers==0.0.28)\n  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->xformers==0.0.28) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->xformers==0.0.28) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->xformers==0.0.28) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->xformers==0.0.28) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->xformers==0.0.28) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->xformers==0.0.28) (2024.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1->xformers==0.0.28)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1->xformers==0.0.28)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1->xformers==0.0.28)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1->xformers==0.0.28)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1->xformers==0.0.28)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1->xformers==0.0.28)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1->xformers==0.0.28)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1->xformers==0.0.28)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1->xformers==0.0.28)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1->xformers==0.0.28)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1->xformers==0.0.28)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==3.0.0 (from torch==2.4.1->xformers==0.0.28)\n  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->xformers==0.0.28) (12.6.85)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->xformers==0.0.28) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->xformers==0.0.28) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->xformers==0.0.28) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->xformers==0.0.28) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->xformers==0.0.28) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->xformers==0.0.28) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->xformers==0.0.28) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->xformers==0.0.28) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->xformers==0.0.28) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->xformers==0.0.28) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->xformers==0.0.28) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->xformers==0.0.28) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->xformers==0.0.28) (2024.2.0)\nDownloading xformers-0.0.28-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m224.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m00:01\u001b[0m","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile utils_new_mod.py\nimport torch\nimport torch.nn as nn\nimport importlib\nimport torch.nn.functional as F\n\nclass StegNetDecoder(nn.Module):\n   def __init__(self):\n      super(StegNetDecoder, self).__init__()\n\n      self.decoder_layers1 = nn.Conv2d(3,256,kernel_size=3,padding=1)\n      self.decoder_layers2 = nn.Conv2d(256,128,kernel_size=3,padding=1)\n\n      self.decoder_layers3= nn.Conv2d(128,64,kernel_size=3,padding=1)\n      self.decoder_layers4= nn.Conv2d(64,64,kernel_size=3,padding=1)\n\n      self.decoder_layers5= nn.Conv2d(64,32,kernel_size=3,padding=1)\n\n      self.decoder_payload1 =nn.Conv2d(32,16,kernel_size=3,padding=1)\n      self.decoder_payload2 = nn.Conv2d(16,16,kernel_size=3,padding=1)\n      self.decoder_payload3 = nn.Conv2d(16,8 ,kernel_size=3,padding=1)\n      self.decoder_payload4 = nn.Conv2d(8,8,kernel_size=3,padding=1)\n      self.decoder_payload5 = nn.Conv2d(8,3,kernel_size=3,padding=1)\n      self.decoder_payload6 = nn.Conv2d(3,1,kernel_size=3,padding=1)\n\n      self.decoder_source1 = nn.Conv2d(32,16,kernel_size=3,padding=1)\n      self.decoder_source2 = nn.Conv2d(16,16,kernel_size=3,padding=1)\n      self.decoder_source3 = nn.Conv2d(16,8,kernel_size=3,padding=1)\n      self.decoder_source4 = nn.Conv2d(8,8,kernel_size=3,padding=1)\n      self.decoder_source5 = nn.Conv2d(8,3,kernel_size=3,padding=1)\n      self.decoder_source6 = nn.Conv2d(3,3,kernel_size=3,padding=1)\n\n   def forward(self,img_w):\n       \n#       img_w = img_w.view((-1,3,32,32))\n      img_w = F.relu(self.decoder_layers1(img_w))\n      img_w = F.relu(self.decoder_layers2(img_w))\n\n      img_w = F.relu(self.decoder_layers3(img_w))\n      img_w = F.relu(self.decoder_layers4(img_w))\n\n      init_d = F.relu(self.decoder_layers5(img_w))\n\n      img_w = F.relu(self.decoder_payload1(init_d))\n      img_w = F.relu(self.decoder_payload2(img_w))\n      \n      img_w = F.relu(self.decoder_payload3(img_w))\n      img_w = F.relu(self.decoder_payload4(img_w))\n\n      img_w=F.relu(self.decoder_payload5(img_w))\n      decoded_payload = self.decoder_payload6(img_w)\n\n      img_w = F.relu(self.decoder_source1(init_d))\n      img_w = F.relu(self.decoder_source2(img_w))\n\n      img_w = F.relu(self.decoder_source3(img_w))\n      img_w = F.relu(self.decoder_source4(img_w))\n\n      img_w = F.relu(self.decoder_source5(img_w))\n      decoded_source = self.decoder_source6(img_w)\n\n      return decoded_payload\n\n\ndef get_steg_decoder():\n   decoder= StegNetDecoder();\n   return decoder\n\ndef get_decoder_ckpt(ckpt_path):\n   ckpt = torch.load(ckpt_path,map_location=\"cpu\")\n   decoder_ckpt =  {k: v for k, v in ckpt['model_state_dict'].items() if 'decoder_' in k}\n   return decoder_ckpt\n   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:33:07.368929Z","iopub.execute_input":"2025-02-03T04:33:07.369242Z","iopub.status.idle":"2025-02-03T04:33:07.375381Z","shell.execute_reply.started":"2025-02-03T04:33:07.369213Z","shell.execute_reply":"2025-02-03T04:33:07.374650Z"}},"outputs":[{"name":"stdout","text":"Writing utils_new_mod.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install torch-fidelity\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:33:09.348492Z","iopub.execute_input":"2025-02-03T04:33:09.348805Z","iopub.status.idle":"2025-02-03T04:33:12.859036Z","shell.execute_reply.started":"2025-02-03T04:33:09.348778Z","shell.execute_reply":"2025-02-03T04:33:12.858176Z"}},"outputs":[{"name":"stdout","text":"Collecting torch-fidelity\n  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (11.0.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (1.10.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (2.4.1)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (0.19.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (2024.9.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torch-fidelity) (12.6.85)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-fidelity) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-fidelity) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-fidelity) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-fidelity) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-fidelity) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch-fidelity) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-fidelity) (2024.2.0)\nDownloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\nInstalling collected packages: torch-fidelity\nSuccessfully installed torch-fidelity-0.3.0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"%%writefile headers.py\nimport argparse\nimport json\nimport os\nimport sys\nfrom copy import deepcopy\nfrom omegaconf import OmegaConf\nfrom pathlib import Path\nfrom typing import Callable, Iterable\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nimport torchvision\nimport utils\nimport utils_img\nimport utils_model\nimport torchvision.transforms as T\nsys.path.append('src')\nfrom ldm.models.autoencoder import AutoencoderKL\nfrom ldm.models.diffusion.ddpm import LatentDiffusion\nfrom loss.loss_provider import LossProvider\nimport utils_new_mod\nimport os\nimport tempfile\n# from PIL\n# from calculatefid import calculate_fid\nfrom pytorch_fid.fid_score import InceptionV3, calculate_frechet_distance\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nfrom skimage.metrics import structural_similarity as ssim\nimport matplotlib.pyplot as plt\nimport torchvision.utils as vutils\nfrom torch_fidelity import calculate_metrics\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:33:12.860131Z","iopub.execute_input":"2025-02-03T04:33:12.860412Z","iopub.status.idle":"2025-02-03T04:33:12.865652Z","shell.execute_reply.started":"2025-02-03T04:33:12.860381Z","shell.execute_reply":"2025-02-03T04:33:12.864807Z"}},"outputs":[{"name":"stdout","text":"Writing headers.py\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"%%writefile centerembed.py\nimport headers\nimport torch\ndef embed_watermark_in_center(imgs_z: torch.Tensor, watermark_z: torch.Tensor,alpha:float=0.9):\n    \"\"\"\n    Embeds the watermark into the center of the latent space.\n    \n    Args:\n        imgs_z: Latent representation of the cover images (b, z, h/f, w/f)\n        watermark_z: Latent representation of the watermark (b, z, h_wm/f, w_wm/f)\n    # \n    Returns:\n        Modified latent space with the watermark embedded in the center.\n    \"\"\"\n    # Get shapes of latent and watermark\n    b, z, h_lat, w_lat = imgs_z.shape\n    _, _, h_wm, w_wm = watermark_z.shape\n\n    # Calculate center coordinates\n    center_h = h_lat // 2\n    center_w = w_lat // 2\n\n    # Determine the region in the latent space where the watermark will be embedded\n    h_start = center_h - h_wm // 2\n    h_end = center_h + h_wm // 2\n    w_start = center_w - w_wm // 2\n    w_end = center_w + w_wm // 2\n\n    # Embed watermark into the center of latent space\n    imgs_z[:, :, h_start:h_end, w_start:w_end] = (\n        (1 - alpha) * imgs_z[:, :, h_start:h_end, w_start:w_end] + alpha * watermark_z\n    )\n\n    return imgs_z","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:33:13.088097Z","iopub.execute_input":"2025-02-03T04:33:13.088304Z","iopub.status.idle":"2025-02-03T04:33:13.093076Z","shell.execute_reply.started":"2025-02-03T04:33:13.088286Z","shell.execute_reply":"2025-02-03T04:33:13.092419Z"}},"outputs":[{"name":"stdout","text":"Writing centerembed.py\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%%writefile txt2img.py\nimport argparse, os\nimport cv2\nimport sys\nsys.path.append('src')\nimport torch\nimport numpy as np\nfrom omegaconf import OmegaConf\nfrom PIL import Image\nfrom tqdm import tqdm, trange\nfrom itertools import islice\nfrom einops import rearrange\nfrom torchvision.utils import make_grid\nfrom pytorch_lightning import seed_everything\nfrom torch import autocast\nfrom contextlib import nullcontext\n# from imwatermark import WatermarkEncoder\nfrom ldm.util import instantiate_from_config\nfrom ldm.models.diffusion.ddim import DDIMSampler\nfrom ldm.models.diffusion.plms import PLMSSampler\nfrom ldm.models.diffusion.dpm_solver import DPMSolverSampler\n\ntorch.set_grad_enabled(False)\n\ndef chunk(it, size):\n    it = iter(it)\n    return iter(lambda: tuple(islice(it, size)), ())\n\ndef insert_watermark_in_latents(samples, watermark_latent, alpha=0.05):\n    \"\"\"\n    Inserts an imperceptible watermark into the latent representation.\n\n    Args:\n        samples (torch.Tensor): The latent representation of the image (B, C, H, W).\n        watermark_latent (DiagonalGaussianDistribution): The latent representation of the watermark.\n        alpha (float): Scaling factor for the watermark (default: 0.1, adjust as needed).\n\n    Returns:\n        torch.Tensor: The modified latent representation with the imperceptible watermark.\n    \"\"\"\n    # Ensure watermark_latent is sampled correctly\n    if hasattr(watermark_latent, 'sample'):\n        watermark_latent_tensor = watermark_latent.sample()  # Call sample as a method\n    else:\n        raise TypeError(f\"Expected a DiagonalGaussianDistribution, got {type(watermark_latent)}\")\n\n    # Get the shape of the watermark latent tensor\n    wm_h, wm_w = watermark_latent_tensor.shape[2], watermark_latent_tensor.shape[3]\n\n    # Compute the center of the image latent tensor\n    center_h, center_w = samples.shape[2] // 2, samples.shape[3] // 2\n\n    # Determine the position to insert the watermark\n    start_h, start_w = center_h - wm_h // 2, center_w - wm_w // 2\n\n    # Blend the watermark latents into the image latents\n    samples[:, :, start_h:start_h+wm_h, start_w:start_w+wm_w] += alpha * watermark_latent_tensor\n\n    return samples\n\n\ndef load_model_from_config(config, ckpt, device=torch.device(\"cuda\"), verbose=False):\n    print(f\"Loading model from {ckpt}\")\n    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n    if \"global_step\" in pl_sd:\n        print(f\"Global Step: {pl_sd['global_step']}\")\n    sd = pl_sd[\"state_dict\"]\n    model = instantiate_from_config(config.model)\n    m, u = model.load_state_dict(sd, strict=False)\n    if len(m) > 0 and verbose:\n        print(\"missing keys:\")\n        print(m)\n    if len(u) > 0 and verbose:\n        print(\"unexpected keys:\")\n        print(u)\n\n    if device == torch.device(\"cuda\"):\n        model.cuda()\n    elif device == torch.device(\"cpu\"):\n        model.cpu()\n        model.cond_stage_model.device = \"cpu\"\n    else:\n        raise ValueError(f\"Incorrect device name. Received: {device}\")\n    model.eval()\n    return model\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--prompt\",\n        type=str,\n        nargs=\"?\",\n        default=\"a professional photograph of an astronaut riding a triceratops\",\n        help=\"the prompt to render\"\n    )\n    parser.add_argument(\n        \"--outdir\",\n        type=str,\n        nargs=\"?\",\n        help=\"dir to write results to\",\n        default=\"outputs/txt2img-samples\"\n    )\n    parser.add_argument(\n        \"--steps\",\n        type=int,\n        default=50,\n        help=\"number of ddim sampling steps\",\n    )\n    parser.add_argument(\n        \"--plms\",\n        action='store_true',\n        help=\"use plms sampling\",\n    )\n    parser.add_argument(\n        \"--dpm\",\n        action='store_true',\n        help=\"use DPM (2) sampler\",\n    )\n    parser.add_argument(\n        \"--fixed_code\",\n        action='store_true',\n        help=\"if enabled, uses the same starting code across all samples \",\n    )\n    parser.add_argument(\n        \"--ddim_eta\",\n        type=float,\n        default=0.0,\n        help=\"ddim eta (eta=0.0 corresponds to deterministic sampling\",\n    )\n    parser.add_argument(\n        \"--n_iter\",\n        type=int,\n        default=1,\n        help=\"sample this often\",\n    )\n    parser.add_argument(\n        \"--H\",\n        type=int,\n        default=512,\n        help=\"image height, in pixel space\",\n    )\n    parser.add_argument(\n        \"--W\",\n        type=int,\n        default=512,\n        help=\"image width, in pixel space\",\n    )\n    parser.add_argument(\n        \"--C\",\n        type=int,\n        default=4,\n        help=\"latent channels\",\n    )\n    parser.add_argument(\n        \"--f\",\n        type=int,\n        default=8,\n        help=\"downsampling factor, most often 8 or 16\",\n    )\n    parser.add_argument(\n        \"--n_samples\",\n        type=int,\n        default=1,\n        help=\"how many samples to produce for each given prompt. A.k.a batch size\",\n    )\n    parser.add_argument(\n        \"--n_rows\",\n        type=int,\n        default=0,\n        help=\"rows in the grid (default: n_samples)\",\n    )\n    parser.add_argument(\n        \"--ldm_decoder_ckpt\",\n        type=str,\n        default=None,\n        # default=\"/kaggle/input/forstatistics/checkpoint_009.pth\",\n    )\n    parser.add_argument(\n        \"--scale\",\n        type=float,\n        default=3.0,\n        help=\"unconditional guidance scale: eps = eps(x, empty) + scale * (eps(x, cond) - eps(x, empty))\",\n    )\n    parser.add_argument(\n        \"--from-file\",\n        type=str,\n        help=\"if specified, load prompts from this file, separated by newlines\",\n    )\n    parser.add_argument(\n        \"--config\",\n        type=str,\n        default=\"configs/stable-diffusion/v2-inference.yaml\",\n        help=\"path to config which constructs model\",\n    )\n    parser.add_argument(\n        \"--ckpt\",\n        type=str,\n        help=\"path to checkpoint of model\",\n    )\n    parser.add_argument(\n        \"--seed\",\n        type=int,\n        default=42,\n        help=\"the seed (for reproducible sampling)\",\n    )\n    parser.add_argument(\n        \"--precision\",\n        type=str,\n        help=\"evaluate at this precision\",\n        choices=[\"full\", \"autocast\"],\n        default=\"autocast\"\n    )\n    parser.add_argument(\n        \"--repeat\",\n        type=int,\n        default=1,\n        help=\"repeat each prompt in file this often\",\n    )\n    parser.add_argument(\n        \"--device\",\n        type=str,\n        help=\"Device on which Stable Diffusion will be run\",\n        choices=[\"cpu\", \"cuda\"],\n        default=\"cuda\"\n    )\n    parser.add_argument(\n        \"--torchscript\",\n        action='store_true',\n        help=\"Use TorchScript\",\n    )\n    parser.add_argument(\n        \"--ipex\",\n        action='store_true',\n        help=\"Use Intel® Extension for PyTorch*\",\n    )\n    # parser.add_argument(\n    #     \"--bf16\",\n    #     action='store_true',\n    #     help=\"Use bfloat16\",\n    # )\n    opt = parser.parse_args()\n    return opt\n\ndef main(opt):\n    seed_everything(opt.seed)\n\n    config = OmegaConf.load(f\"{opt.config}\")\n    device = torch.device(\"cuda\") if opt.device == \"cuda\" else torch.device(\"cpu\")\n    model = load_model_from_config(config, f\"{opt.ckpt}\", device)\n    # Parameter None for clutil sweep\n    print(f'reload decoder weights {opt.ldm_decoder_ckpt}...')\n    if opt.ldm_decoder_ckpt is not None and opt.ldm_decoder_ckpt.lower() == \"none\":\n        opt.ldm_decoder_ckpt = None\n    if opt.ldm_decoder_ckpt is not None:\n        state_dict = torch.load(opt.ldm_decoder_ckpt)['ldm_decoder']\n        # state_dict = torch.load(opt.ldm_decoder_ckpt)['state_dict']\n        # state_dict = {k.replace('first_stage_model.', ''): v for k, v in state_dict.items() if 'decoder' in k or 'post_quant_conv' in k}\n        msg = model.first_stage_model.load_state_dict(state_dict, strict=False)\n        model.eval()\n        print(msg)\n\n    if opt.plms:\n        sampler = PLMSSampler(model, device=device)\n    elif opt.dpm:\n        sampler = DPMSolverSampler(model, device=device)\n    else:\n        sampler = DDIMSampler(model, device=device)\n\n    os.makedirs(opt.outdir, exist_ok=True)\n    outpath = opt.outdir\n    batch_size = opt.n_samples\n    n_rows = opt.n_rows if opt.n_rows > 0 else batch_size\n    if not opt.from_file:\n        prompt = opt.prompt\n        assert prompt is not None\n        data = [batch_size * [prompt]]\n    else:\n        print(f\"reading prompts from {opt.from_file}\")\n        with open(opt.from_file, \"r\") as f:\n            data = f.read().splitlines()\n            data = [p for p in data for i in range(opt.repeat)]\n            data = list(chunk(data, batch_size))\n\n    sample_path = os.path.join(outpath, \"sampleswater50k\")\n    os.makedirs(sample_path, exist_ok=True)\n    sample_count = 0\n    base_count = len(os.listdir(sample_path))\n    grid_count = len(os.listdir(outpath)) - 1\n\n    start_code = None\n    if opt.fixed_code:\n        start_code = torch.randn([opt.n_samples, opt.C, opt.H // opt.f, opt.W // opt.f], device=device)\n        \n    if opt.torchscript or opt.ipex:\n        transformer = model.cond_stage_model.model\n        unet = model.model.diffusion_model\n        decoder = model.first_stage_model.decoder\n        additional_context = torch.cpu.amp.autocast() if opt.bf16 else nullcontext()\n        shape = [opt.C, opt.H // opt.f, opt.W // opt.f]\n\n        if opt.bf16 and not opt.torchscript and not opt.ipex:\n            raise ValueError('Bfloat16 is supported only for torchscript+ipex')\n        if opt.bf16 and unet.dtype != torch.bfloat16:\n            raise ValueError(\"Use configs/stable-diffusion/intel/ configs with bf16 enabled if \" +\n                             \"you'd like to use bfloat16 with CPU.\")\n        if unet.dtype == torch.float16 and device == torch.device(\"cpu\"):\n            raise ValueError(\"Use configs/stable-diffusion/intel/ configs for your model if you'd like to run it on CPU.\")\n\n        if opt.ipex:\n            import intel_extension_for_pytorch as ipex\n            bf16_dtype = torch.bfloat16 if opt.bf16 else None\n            transformer = transformer.to(memory_format=torch.channels_last)\n            transformer = ipex.optimize(transformer, level=\"O1\", inplace=True)\n\n            unet = unet.to(memory_format=torch.channels_last)\n            unet = ipex.optimize(unet, level=\"O1\", auto_kernel_selection=True, inplace=True, dtype=bf16_dtype)\n\n            decoder = decoder.to(memory_format=torch.channels_last)\n            decoder = ipex.optimize(decoder, level=\"O1\", auto_kernel_selection=True, inplace=True, dtype=bf16_dtype)\n\n        if opt.torchscript:\n            with torch.no_grad(), additional_context:\n                # get UNET scripted\n                if unet.use_checkpoint:\n                    raise ValueError(\"Gradient checkpoint won't work with tracing. \" +\n                    \"Use configs/stable-diffusion/intel/ configs for your model or disable checkpoint in your config.\")\n\n                img_in = torch.ones(2, 4, 96, 96, dtype=torch.float32)\n                t_in = torch.ones(2, dtype=torch.int64)\n                context = torch.ones(2, 77, 1024, dtype=torch.float32)\n                scripted_unet = torch.jit.trace(unet, (img_in, t_in, context))\n                scripted_unet = torch.jit.optimize_for_inference(scripted_unet)\n                print(type(scripted_unet))\n                model.model.scripted_diffusion_model = scripted_unet\n\n                # get Decoder for first stage model scripted\n                samples_ddim = torch.ones(1, 4, 96, 96, dtype=torch.float32)\n                scripted_decoder = torch.jit.trace(decoder, (samples_ddim))\n                scripted_decoder = torch.jit.optimize_for_inference(scripted_decoder)\n                print(type(scripted_decoder))\n                model.first_stage_model.decoder = scripted_decoder\n\n        prompts = data[0]\n        print(\"Running a forward pass to initialize optimizations\")\n        uc = None\n        if opt.scale != 1.0:\n            uc = model.get_learned_conditioning(batch_size * [\"\"])\n        if isinstance(prompts, tuple):\n            prompts = list(prompts)\n\n        with torch.no_grad(), additional_context:\n            for _ in range(3):\n                c = model.get_learned_conditioning(prompts)\n            samples_ddim, _ = sampler.sample(S=5,\n                                             conditioning=c,\n                                             batch_size=batch_size,\n                                             shape=shape,\n                                             verbose=False,\n                                             unconditional_guidance_scale=opt.scale,\n                                             unconditional_conditioning=uc,\n                                             eta=opt.ddim_eta,\n                                             x_T=start_code)\n            print(\"Running a forward pass for decoder\")\n            for _ in range(3):\n                x_samples_ddim = model.decode_first_stage(samples_ddim)\n\n    precision_scope = autocast if opt.precision==\"autocast\" or opt.bf16 else nullcontext\n    with torch.no_grad(), \\\n        precision_scope(opt.device), \\\n        model.ema_scope():\n            all_samples = list()\n            for n in trange(opt.n_iter, desc=\"Sampling\"):\n                for prompts in tqdm(data, desc=\"data\"):\n                    uc = None\n                    if opt.scale != 1.0:\n                        uc = model.get_learned_conditioning(batch_size * [\"\"])\n                    if isinstance(prompts, tuple):\n                        prompts = list(prompts)\n                    c = model.get_learned_conditioning(prompts)\n                    shape = [opt.C, opt.H // opt.f, opt.W // opt.f]\n                    samples, _ = sampler.sample(S=opt.steps,\n                                                     conditioning=c,\n                                                     batch_size=opt.n_samples,\n                                                     shape=shape,\n                                                     verbose=False,\n                                                     unconditional_guidance_scale=opt.scale,\n                                                     unconditional_conditioning=uc,\n                                                     eta=opt.ddim_eta,\n                                                     x_T=start_code)\n                    # watermark_image = Image.open('/kaggle/input/mnistasjpg/testSet/testSet/img_100.jpg').convert('RGB')\\  # assuming RGB for color watermark\n                    watermark_image = Image.open('/kaggle/input/fashion-mnist-png/train/1/10012.png').convert('RGB')\n                    watermark_image = watermark_image.resize((32, 32), Image.Resampling.LANCZOS)\n                    watermark_tensor = torch.tensor(np.array(watermark_image), dtype=torch.float32)  # Normalize to [0, 1]\n                    watermark_tensor = watermark_tensor.permute(2, 0, 1).unsqueeze(0)  # Add batch dim and change channel order to CxHxW\n                    # watermark_tensor = watermark_tensor.unsqueeze(0).unsqueeze(0)\n            # Pass the watermark through the encoder to get the latent representation\n                    watermark_latent = model.encode_first_stage(watermark_tensor.to(opt.device))  # Assuming an encoder method exists\n            # Insert the watermark latent into the samples\n                    modified_latents = insert_watermark_in_latents(samples, watermark_latent)\n                    # x_samples = model.decode_first_stage(samples)\n                    if opt.ldm_decoder_ckpt is not None and opt.ldm_decoder_ckpt.lower() == \"none\":\n                        x_samples = model.decode_first_stage(samples)\n                    else:\n                        x_samples = model.decode_first_stage(modified_latents)\n                    x_samples = torch.clamp((x_samples + 1.0) / 2.0, min=0.0, max=1.0)\n\n                    for x_sample in x_samples:\n                        x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')\n                        img = Image.fromarray(x_sample.astype(np.uint8))\n                        # img = put_watermark(img, wm_encoder)\n                        img.save(os.path.join(sample_path, f\"{base_count:05}.png\"))\n                        base_count += 1\n                        sample_count += 1\n\n                    all_samples.append(x_samples)\n\n            # # additionally, save as grid\n            # grid = torch.stack(all_samples, 0)\n            # grid = rearrange(grid, 'n b c h w -> (n b) c h w')\n            # grid = make_grid(grid, nrow=n_rows)\n\n            # # to image\n            # grid = 255. * rearrange(grid, 'c h w -> h w c').cpu().numpy()\n            # grid = Image.fromarray(grid.astype(np.uint8))\n            # # grid = put_watermark(grid, wm_encoder)\n            # grid.save(os.path.join(outpath, f'grid-{grid_count:04}.png'))\n            # grid_count += 1\n\n    print(f\"Your samples are ready and waiting for you here: \\n{outpath} \\n\"\n          f\" \\nEnjoy.\")\n\nif __name__ == \"__main__\":\n    opt = parse_args()\n    main(opt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T10:16:39.842195Z","iopub.execute_input":"2025-02-09T10:16:39.842545Z","iopub.status.idle":"2025-02-09T10:16:39.850889Z","shell.execute_reply.started":"2025-02-09T10:16:39.842518Z","shell.execute_reply":"2025-02-09T10:16:39.850129Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Overwriting txt2img.py\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"%%writefile for1k.txt\nA teddy bear sitting next to a picture of himself on a sandy beach and other travel memorabilia.\nA large variety of apples lined up at the store.\nGray cat with green eyes looking at camera while lying on a pink toy.\ndried flowers extend from the opening of a black vase with a white brick wall in the background.\nTwo skiers on a field with the sun shining.\na person sitting on a ledge with a bike near by\nAn open clean, white bidet is on display.\nsomething round being cooked in a shape of a pancake in a fry pan\nBlue seats in a bus in a city.\nA table with a couple of bears on it.\nThree sheep walk down a path behind a man. \nA tall sandwich with pickle on a white plate.\na public transit bus on a city street \nChicken with chies and red peppers, rice, carrots and broccoli.\nLooking down at a desktop with two monitors, a key board, mouse and cell phones on it.\nThe people in the photo are all reaching your hands up high.\nA image of a cat at the doorstep looking outside\nA man on a surfboard riding a wave.\nA man holding a banana in his hand.\nA small child is holding a teddy bear.\nThere is a crossing sign next to the car. \nthis bathroom has a wooden cabinet and a sink on top\nA knife is sitting on a plate of food\nA child standing next to a bed with a laptop.\na man in a black suit gazing a round\na vase with a flower growing very well\nA guy in a black shirt charging his cell phone.\nA group of people that are holding onto sheep.\nA black cat wears a bumblebee hat on its head. \nBridge with arches over lake with metropolitan buildings in background\nThere is a bird sitting on a tree branch.\nA bird on the edge of a boat in a body of water.\nThere is a plate of food and a pizza on a table.\nAn old time car is parked at the curb near a stop sign.\nThe tennis player's ball is in mid air.\na wood bench is outside covered in snow\nA large pizza sitting on top of a pizza pan.\nA bench in th side of a city street next to a window\nA black cay laying on top of a suitcase. \na fat girl blowing out candles on a cake\nA man has thrown a frisbee into a metal structure.\na brown donut on some white paper on a red counter\na person in a red top is laying on a brown couch\nThe zebra stands and looks down at the ground.\nGroup of spoiled fruit sitting next to each other. \nTwo people on hose back riding through a fair while a woman in the foreground talks on a cellphone.\nA jet that is flying in the sky.\nA small group of construction workers by a crosswalk.\nA person bicycles along the edge of the road overlooking the river.\nTwo giraffes are in the grass by some rocks.\nA street with sign, lamppost and many trees.\nTwo people dressed in black, one with a green mask.\na man on a cell phone holding a microphone up to his ear\na man in a chefs outfit standing by a big donut\nThe horse is eating grass from the ground.\nA black cat staring at the camera taking the picture.\nA blurred train is going under a bridge.\nTwo screens show two unique pairs of wings.\na woman with eye glasses in front of a pair of birds\nToilet in a small room with plant pots.\na close up of a parking meter \nA kitchen slab on which there is a microwave and few cups are kept in a tray. \nA baby elephant walks between the legs of its mother.\nA clean knife and french bread sit on a cutting board.\nA baseball batter is swinging a bat at an incoming pitch.\nAn open partially packed suitcase resting on the floor with a cell phone next to it.\nA car is stopped at a red stop light.\na hand is holding a knife that is cutting some cake\nsome giraffes a building trees rocks dirt and plants\na tiled floor with a toilet sitting on top of it \nAutomobiles stopped at an intersection because of a passing train. \nA girl in plain dress standing next to a white teddy bear.\nA man bends over in the snow in sight of a mountain range.\nA cutting board with broccoli being prepared for a meal.\nA foot that is on top of a banana.\nTwo stuffed bears have shirts on their heads. \nsome people on skis ride on the snow \nOld baseball bats are turned into a seat.\na room showing a very big fridge and a dining table\nA rusted out train engine sitting next to a green forest.\nA woman walking with a man and holding an umbrella looks off to the side. \nA young girl holding a piece of food and her hand over her mouth.\nA skateboarder preforming tricks on a half pipe. \nA man is leaning back talking on the phone\nA group of bikers riding bikes down a street.\na giraffe is standing in a grassy field \nFour zebras and a nearby giraffe on some grass.\nA man sitting inside an outdoor fruit market.\na close up of a zebra behind a fence \nA suit case is opened and there are things cluttered around\na red and yellow fire truck and some buildings\nstream running beside a railroad track in the mountains.\nA tennis player prepares to hit a ball during a match.\nA little brown bird sitting by a window.\nThe light shines on a cluttered desk with a laptop on it.\nThe large cargo train is green and yellow.\nFour people are flying kites on a beach.\nA plane that is taking off at an airport\nA group of ninjas wearing all black hold up small white fans.\nA bathroom with urinals that have graffiti above them\nA cat laying on top of a computer keyboard.\nsome kind of nasty bathroom that I would never use.\nA baby lays inside of a small, open suitcase.\nskiers riding on a ski lift to the top of a mountain\nTwo women are smiling as one of them holds a menu.\nA man in uniform with a cell phone up to his ear.\nTwo very cute fuzzy young sheep on  a grassy hill.\na lady with green hair sitting next to a horse\nA person sitting down with their legs stretched in front of them, on a skateboard ramp with a skateboard several feet in front of them.\nthere is a small vase with many tulips in it\nA man in a wet suit surfs a wave.\nA group of women running after a soccer ball\nTwo adults with umbrellas and two children walking in the rain. \nTwo sun shaped mirrors are above bowl shaped sinks.\nA group of men in red vests rowing a dragon boat.\nA group of people in the woods with dogs.\nBuildings with a clock and a crane over head are in this picture. \nPeople mingling on a beach with a kite floating in the sky.\nA cat laying on a bed next to a laptop.\nA sleeping grey husky wearing a green bandana.\nA batter getting ready to hit his pitch.\nA plate containing a slice of dessert, two forks and some piped cream\na lady eating at a table holding up the peace sign\nA crooked one way sign pointing into the ground\nA couple of slices of a cinnamon roll on a white plate.\nA park bench made out of wood in the park. \nA picture of a young woman holding hands with a dog.\nA dog with its paw on a remote controller on a couch.\nA baseball player running the bases at a game \nthe bathroom has a mirror and a tiled sink\nSeveral elephants in the water with one up close standing next to a trainer \nA rear view mirror with a large red semi truck.\nA little child standing next to a toy dump truck.\nA toothbrush being held under a water facet.\nBlack parking meter on sidewalk in urban street setting.\nAn orange cat rests on a white counter top\nPeeled and cut  plantains are getting coated with seasons .\nA bus turning at the intersection of a city street\nA white bathroom mirror mounted to it's wall.\nA group of people walking down a  street on a wet sidewalk.\nA cat that is sitting on some cushions.\nPeople walk through the street with umbrellas to shade the sun.\nSome very cute sheep standing in a room with smiling faces. \nMany people play sports in a grass field. \na public transit bus on a city street\nA flock of birds flying in an overcast sky\na small bird on the ground in a field\nThe giraffe is looking into the back window of a car. \nA half eaten hot dog being held in a hand at a baseball game.\nAn outdoor kitchen area with chefs and a stove.\nA umbrella that has multiple different colors on it.\nA remote control has all black and white buttons except for a yellow \"Light\" button.\nRed bus with graffiti stops to pick up passenger.\na big bathroom with a very large bath tub\nA man on a skateboard is jumping over a pile of blocks.\nThis is a very ornate building with a clock on it.\nA young woman poses comically with a piece of pizza in her mouth.\nA man in a large room with baskets and pottery\nSepia photograph of small elephants in a wildlife park\nTwo people are sitting on a bench together in front of water.\nA woman with a bowl of food and seated\nA refrigerator full of juice and soda next to a microwave. \na gray and white bathroom with a sink mirror and toilet\nTwo white birds are on an elephant's back.\nA large stork spreads it's wings as it lands.\nA girl flying a kite on the beach.\nA brown teddy bear in a forest with trees and shrubbery.\nA man wearing a red hat and a suit and tie.\na red bus is in front of another one\nSome people are standing on a crowd crowded sidewalk\nA clock is sitting at the top of the tower.\nThe signs give the street names and show where to park.\nA surfer wearing red shirt surfing on a wave.\nA green train traveling through a train yard.\nA clock on top of a signpost stands in front of a building.\nA young man sitting in front of a white piano.\na street sign on the corner of a city street \nA man and a woman posing together for a picture\nThe large train is black, yellow, and red.\nA person in a mid air jump while skiing on a snowy slope.\nA kitchen area with refrigerator, counter and a microwave.\na bunch of cement blocks stacked side by side in front of umbrellas\nThe young skateboarder is trying one of his first tricks.\nThe bird is walking beside a bull with dark horns.\nA toilet is in a dirty bathroom with a sink.\nA person riding a skateboard next to the ocean.\na small toilet in a bathroom in a portable vehicle\nA dog has crazy eyes as he tries to keep the frisbee.\nA park at night is shown, with an empty bench centered\nA man standing in front of a table with a plate of oysters.\none laptop two monitors two keyboards and two mice\nA small room built from legos with a tiled floor.\na big sign sits above a building \nA white toilet sitting inside of a bathroom stall.\nA ram stands alone in grass between large rocks.\nA table has three wine glasses, several bottles of wine, and a bowl of salad.\nA little girl with a baseball bat is waiting for the pitch.\nThere is a Christmas tree in a living room.\nA train is traveling down the railroad tracks. \nA very primitive ferry holds a truck and three occupants.\nA woman is outside preparing to fly a kite\na number of people in a room with a person playing nintendo wii\na collage of photos with four fire hydrants \nA collection of various street signs by a big building.\nA couple of birds fly through a blue cloudy sky.\na woman biting into a large slice of cheese pizza \nA guy on a skate board on a big ramp.\nTwo women, one with a black helmet and one with a red helmet sit on a white scooter.\nA man is cross country skiing in a field.\nA group of cattle are gathered under a shade tree.\nAn elephant is looking out through a thick rope fence.\nAn elephant that is very close to the camera. \nA cobblestone city street lined with buildings on a sunny day\nA man riding skis down a snow covered mountain.\na silver and black stove and microwave a sink and cabinets\na herd of giraffes eat on some tree leafs \na couple of sheep walking across a grass covered field.\nPeople on corner with cars on street and stoplight with building\nA stoplight with a road sign on it \nThis is an outdoor restroom that is handicap accessible. \nLamps are the only lighting in this kitchen. \na cat is laying on a window ledge\nA parking garage, with a green painted floor, full of scooters\nTwo Nintendo Wii remote controllers that are white with one of them on a stand.\na woman holding a plate with some colorful slices of cake on it\nMan in white shirt holding up a cellphone in a crowd. \nTABLE WITH A PLATE OF FOOD A DRINK, CELL PHONE AND A COMPUTER\nThere is a plate filled with pasta and vegetables.\nThe dual image shows people carrying their surfboards under their arms.\nA black dog in a yard jumps up toward a yellow Frisbee.\nStores, people, street signs and cars on a street.\nA Metro bus line departs its terminus station\nA fridge with its doors opens stands in a room.\na number of cars on a street with traffic lights \nLarge assortment of vegetables displayed for sale on large round table.\nThree surfers in wetsuits going in to the ocean\na couple of people that are standing up by a surfboard\nRows of boats are docked along a waterway.\nAn umbrella is placed inside an old microwave. \nA group of people dressed in an elephant costume.\nA bathroom with two toilets and a shower in it, with no space for any of them.\nThe white cat is sitting underneath an umbrella \nA man in glasses is wearing a tie with extraterrestrials on it.\nA large marble bathroom with mirrored closet and jetted tub.\n A man wearing a dress shirt and a tie sitting against a dark background. \nA pole on a city street covered with signs and stickers in front of a blue crane.\nA person that is holding an umbrella in her left hand.\nA person kiteboarding over waves in the ocean.\nA still image multi shot of a man on a skateboard doing tricks on the ramp\nA chocolate donut and cup of coffee on a napkin.\nThe locomotive of a train is painted yellow.\nA street with a traffic light under a cloudy sky.\na close up of two people playing soccer\nSeveral people on skis either standing, walking or skiing down the slope. \nThe sweet dish features bananas on top of the crust..\nA bus is parked and waiting on passengers \nA man holds a black plate with a square skull in front of his face.\nBicycle rick shaw with umbrella and rain canopy\nA man flying a kite over a snow covered field.\nA small black and brown dog standing next to a cow.\nAn object is seen here in this unique image.\nA made bed in a hotel, with a mirror on the wall behind it.\nA person holding a cell phone in their hands.\nA young bride smiles at the crowd while she and her groom cut the cake. \na number of horses in a field with a sky background\nA pizza cutter is designed to look like the Enterprise\nA zebra standing beside a tree at the zoo.\nA man sitting on the park bench in the forest \nA huge clock on the side of a building.\nA white toilet is separated from a brown shower curtain.\n a close up of a clock face saying it is a little after 2 o'clock\nA baseball player followed by a small child walking on a baseball field \nA pole with signs on it in the street out side.\nA man jumping in the air in a horizontal direction over the top of a bed.\nA laptop computer is on a glass table on a balcony.\nA man is approaching a seagull on the beach.\nBowls of food are sitting on a table.\nA basic cafeteria breakfast on a plastic tray\nA clock sitting next to a brick sign under palm trees.\nA batter swings at a pitch during a baseball game.\nA couple of chairs that are in a room.\nA man is enjoying a day snow skiing. \nsomeones room with a purple bed and paper everywhere \nA smiling woman looks to be playing a Wii.\nA man that is laying down in a bed.\nA large bus carrying several passengers drives through a busy part of town\nA little girl is getting ready to blow out a candle on a small dessert.\nFour boxes of pizza are opened on the table\nThe baseball players slides into safety at home plate.\nA blue crew cab truck sitting in the parking lot of an apartment building.\nA brown cow sits in the middle of a grassy field.\nThe young man is sitting on the suitcases relaxing. \ntwo people sit on a bench behind signs for Carnell Pitts avenue and Cory Hatter avenue\nA street sign displaying multiple cities and their directions.\nA bathroom with a walk in shower currently under repair.\nTwo zebras in an open field with grass.\nA cat stretching its paw over a keyboard. \na plaza filled with a lot of birds and some cows\na black and white dog is in a cage\nAirplane low in the area near an air traffic control tower.\nBunch of apples and oranges sitting on a white surface.\nA horse is standing in the grasses of a field. \nTwo trains with grass and blue skies and power wires.\nThe entire baseball team has gathered on the field for a celebration. \nThe young boy is playing in the living room of his house. \na couple of people that are dressed up dancing\na man standing while holding onto a tennis racket in his right hand\nTwo zebras running on a path next to trees.\nA small square plate of broccoli with seeds and a scoop of rice\nA large airplane flying over a lush green hillside.\nA man on a skateboard flipping the skateboard in the air.\nA man who is diving to hit a tennis ball.\nA cat with it's paw next to a computer mouse on a wooden table.\ntwo laptop computers sit on a countertop, plugged with wires\nThree monitors play a movie on the computer desk.\nTwo young kids playing with letters in the kitchen.  \nA dog sitting in a basket mounted on the front of a blue bike.\nA horse and several cows feed on hay.\nA baseball game is being played before a crowd.\nThis shot is of a crowded highway full of traffic\nA large jetliner flying over a small farm near a forest.\nA man holds a balloon and stuffed bear over the edge of a balcony.\nVirgin sponsored airplane parked with a plane leaving in the background.\nA polar bear is in the water holding on to a disk.\nA train carrying freight containers is on the tracks.\nThere is a scrunchie on top of a laptop computer.\nA little boy sits in front of several tortilla pizzas.\na kitchen with a nasty dirty kitchen with a light beam through the window\nThe caramel-colored kitten is  lying on the small blanket on top of the unmade bed.\nA man that is sitting down with a cellphone.\nSeveral children attentively play a game of curling together.\nA modern and clean bathroom with a big sink.\nA puppy has pulled toilet paper across the bathroom floor.\nA cat sitting on top of a towel.\nTwo men are competing in cross country skiing. \na woman standing with an umbrella over her head \nA crowd of people are gathered in a grassy park.\nTwo bears standing on a grassy hill facing each other. \nShot of various traffic signs and traffic light in city area.\nA man skis over a plastic contraption on a ski slope. \nThree elephants standing in the grass near water.\nA man in a yellow shirt is surfing through the waves.\nA couple posing on a horse statue in a courtyard.\nLooking down at a partially eaten salad sandwich in paper\nPerson holding open a large door to the walk-in refrigerator\nThe man on the phone is looking at the camera and smiling.\nA train traveling on the tracks approaching a station.\nAn Asiana Airlines plane taxiing at an airport.\nA bear shaped cake with lit candles inserted.\nAn assortment of broccoli and cauliflower is arranged.\nA moving truck painted with graffiti is in front of a bank.\nA man holding out two hands as if pulling on something\nA man uses the computer while sitting at a table.\nA train in a city with tall buildings.\nA bed sitting in a bedroom next to a window under pictures.\nthis giraffe looks like it is kissing the tree limb\nA group of men who are posing for a picture together.\na computer and speakers on a wood desk\nA woman in plaid pants posing for a picture on skis.\nTwo women are working on a dessert together\nA small bathroom with a white vanity and a glass shower.\nthere is a big dog that is sitting inside of a luggage\nthis is a man throwing a disc on the beach\nA coffee cup is parked in between two digital parking meters.\nA bird standing alone in the water looking\nA person is looking in the mirror of a motor bike\nthe bathroom has a toilet and a sink and mirror\nA man riding a bike down a dark city street.\nA variety of people stand in a field by a monument.\nA messy room with a laptop on a bed.\nA green double-decker bus parked at a bus stop. \nA big full view of several people gathering.\nPeople are skiing down a long ski slope.\nA transit bus driving down a highway by some fast food restaurants.\nA man that is laying down on a bed.\nA man eats something that is wrapped in white paper.\nA big fancy clock handing from the ceiling.\nA female sitting on her bed looking at a laptop.\nA man paints scenes at a fair stand.\nThree giraffes huddled together watching a zebra and gazelle.\nsome people are riding surf boards in rapids\nA bathroom with a sink, toilet and tub in front of a large mirror.\nTHERE ARE CHRISTMAS DECROATION ALL OVER THE PLACE\nA picture of some people playing with a frisbee.\na large statue of two people standing near a luggage bag\nA boy at a skate park practicing on his skateboard. \nA group of people pose with three bicyclists. \nHorses grazing in a muddy portion of a flooded field\nA table with a piece of construction paper, scissors and sewing thread.\na man standing next to sheep on a lush green park.\nA couple of elephants standing on top of a grass covered field.\nThe young person is surfing on wave in the sea.\nTwo parking meters on a city street. \nA small bathroom, lacking only a toilet tissue dispenser.  \nA couple of yak in their field eating some grass.\nThe basketball players are playing in a game\nSomeone is eating a piece of sandwich next to a glass.\nSome statues of elephants are on blue platforms.\nFirefighters are riding in the back of a fire truck.\nA harbor filled with boats surrounded by buildings.\na close up of a child wearing a shirt and tie kneeling down\nTwo horses grazing in a field near a lighthouse.\nTelevision monitor in room with many items displayed.\nA man on a raft waving a jacket and a surfer in a wet suit out in the ocean\nGiraffes in a zoo, standing with their heads peeking over the fence, looking at people.\nA man touching home plate on a baseball field.\nPeople on surfboards in the blue sea, a woman lying down and a man paddling with an oar.\nTwo large adult cats relaxing on a bed.\nA man talking on a cell phone wearing an orange shirt and baseball cap.\nA white vase with white flowers and two candles on a table.\nLooking through a door and seeing a toilet and sink.\nA view form under a tree of a window\na red and white fire hydrant is sitting by a curb\nA cityscape of a set of train tracks with trains running on them.\nA young soldier has his picture taken with a young lady with an open jacket and brazier showing.\nSmall white bathroom with marble counter tops on the sink. \nblack and white image of a bench in a forest\nA very small kitchen in an attic with a sink  \nThere is a somewhat short train moving along a track\nA polar bear buries its head under the rump of another polar bear.\nA guy in funny hat holding a very big bird.\na plate of broccoli on a table next to some other plates of food \nGroups of people moving down road on skis\nA man is asleep in bed with a laptop open on his lap.\na childrens soccer game in the background, one kid is kicking the ball\nA city fire hydrant next to a taxi cab.\nA plane that is flying in the sky over two houses.\nPedestrians hold umbrellas as they cross the street as snow starts to fall.\na girl that is on a tennis court with a racket\nGirl using her laptop computer while laying on a bed.\nTwo girls are posing outdoors under an umbrella for a photo. \nPeople approaching a line of buses at a busy terminal.\nA jet shoots up into the cloudy sky.\nA frame has six pictures, two with a horse.\nA sign post with signs that read \"Maciel Ln\" and \"Wonder Stump Rd\".\nMan photographing a fresh pizza his tired buddy just wants to eat\nA person holding a smart phone in their left hand.\nA person is riding waves on a canal.\nA blue street sign marks Hollywood Boulevard. \nA group of zebra's eating hay from a trough.\nA man standing in a tunnel next to a car.\nA man holding a red snowboard while standing in snow.\nA group of giraffes eating leaves off trees.\nA dog wrangling a group of sheep in a field.\nA man doing a trick on a wall with a skateboard.\nA picture of a baseball player from a long time ago.\na fence with a mountain in the background\nA man driving a luggage cart sitting on top of a runway.\nBottles and other items on a counter top.\nThere are two people who are out in the snow.\nA group session of children reading books to their dogs.\nA man walking with a drink and a bag while listening to earbud headphones.\nA little boy in a green shirt holding a purple toy.\nA man in a coat in tie wearing a skirt and stockings. \nA man surfs a small wave in calm waters.\nA surfer is riding a wave in light blue water.\nTwo men smile while sitting at a table outdoors.\nA man standing on a type of boat during the day.\nA hot dog in tin foil with mustard, onions and other toppings.\nA hillside near the ocean with a large wall and possibly a road constructed into the hill.\nsome horses standing by a trailer in the snow \nA clock that is sitting behind a window.\nA zebra stands next to rocks by himself. \nA man riding a surfboard while flying a kite.\nA couple of men walking along a river.\nA black and white photo shows a frisbee disc.\nthe lines are black and white and run parallel \nA man wearing a purple neck tie and a V neck sweater.\nThere are three toothbrushes and two bottle of soap on this sink.\na white bird standing on a wooden structure next to a body of water\nA young man standing and posing in a Chicago Cubs baseball uniform.\nA couple of horses standing on top of a grass covered field.\nTwo little girls who are sitting on a couch.\nA man sits in a dimly lit room using a laptop computer.\nA man standing on a mountain top wearing skis.\nA cat that is standing looking through a glass.\nA female skateboarder is in mid air doing a trick.\npeople sitting at the beach, playing in the water, and flying a kite \nMan serving tennis ball and racket with camera watching on court\nA computer sits on a desk by a printer.\nA scared boy holding a baseball glove out towards a baseball.\na man on a giant bicycle rides by a tall pole in front of an empty, large field in front of some mountains\nThe furniture in the small living room is mostly red.\nA young boy is unwrapping paper covering a box.\nMany people skateboard through an intersection, stopping traffic.\nA kitchen with wood floors and one brick wall.\nCabbage, broccoli and other assorted vegetables are arranged on a table.\nTwo urinals with foreign cartoons taped on the tile.\nA collection of silverware resting on a rack.\nSeveral green and red apples lying on ground.\nA laptop computer and a desktop computer on a white desk\nSeveral men playing soccer in a park with a few onlookers.\nAn electronic device displaying the time sitting on a table.\nA woman eating a doughnut sitting at a laptop.\nAn omelette and side of greens on a plate with coffee and a glass of juice. \nA train with it's doors open sitting next to a platform.\nA PINK TOILET AND A PINK BATH TUB IN THE BATHROOM\nTwo surfers make their way to the water carrying surfboards.\nThe little boy is on his skateboard riding outside.\nA nun riding a skateboard down a sidewalk next to parked cars.\nPeople at a restaurant waiting to be served.\nBlack and White cat lays inside of the sink\nThe boy is riding a skateboard off a skate ramp.\nA young zebra is sniffing the ground in a dusty area.\nA woman holding a plate of cake covered in frosting.\nA small cat examines the light in a suitcase.\nA couple of sheep standing in the tall grass.\nA boy carrying two skateboards crosses the street.\nA man has a crow sitting on his hand.\nA family of ducks swimming in the water\nA group of people and a horse are at the edge of the garden in front of the bluff on a sunny day.\nTHERE ARE PEOPLE THAT ARE PLAYING FRISBEE ON THE FIELD \nA white plate with lots topped with garlic bread.\nan older woman walking in the street and a bus \na couple of birds swimming in a lake \nA group of animals standing in the grass.\nA man in the kitchen holding a beverage. \na banana tree in the woods with bananas on it\nA man wearing a bushel of bananas on his head.\nA large clock with flags on it says Colgate.\nA kitchen with a refrigerator freezer next to a sink.\nA clean bathroom with a tub and sink. \nA hard suitcase with reinforced edges on the floor\nA woman on a crowded street with and umbrella and shopping trolly.\nA young boy grinds a rail with his skateboard.\nTwo women bake together at a kitchen island.\nA set of four bikers riding motorcycles side by side.\nA bottle of water near a computer screen and a keyboard with fingers on it.\nA bird on the beach with wings out stretched.\nA tray on a table with plates of food and dipping sauces and a drink.\nthere are many giraffes that are standing by a fence\na black plane is sitting on a runway\nA person that is making something out of wood.\nA woman wearing a purple jacket is shown on skis.\nA woman is standing in the kitchen with another woman.\nZebras and giraffes together in a zoo cage.\nA traffic light next to a blue car in front of a building.\nan image of a child putting food in its mouth\na desk with bananas, a instrument case and a globe sitting on it.\nTraffic signals and sign on pole at roadway intersection.\nA female tennis player watching the ball. \nA close up shot of horse, with it's baby in the back.\nA family is on a beach and a cruise ship is in the background.\nA woman smiles as she stands in skis on a snowy hill.\nA man with a jug and a bucket in a kitchen\nA road sign sitting in front so a billboard.\nZebras munch on feed in a brick and stucco structure.\nA group of jets sitting on top of an airport tarmac.\nA collection of antique pocket watches in various condition\nA team of girl tennis players gather together at the net for a group picture.\na person wearing a black coat and a tie with bolt designs on it.\nA set of women's personal care items sitting on a bed.\nSix plates of the same gourmet dish on a wooden table.\nBlue and yellow passenger train with its doors open on a station. \nA man riding a skateboard down a ramp.\nA horse pulling a cart down a road.\na four engine propeller jet flies through the sky\nA picture of two men in the service on a table below a clock. \nA thick sandwich on a plate with a fork and a pickle.\nA person walking across a desert filled surrounded by mountains.\nA man is swinging a tennis racket at a ball.\nA small blue race car passing by a motorcycle\nA sugar doughnut on a plate with a tall glass of orange juice.\nThe giraffe is standing alone in the field.\nA woman taking a picture of a woman by several pizza's.\nAn oblong tray has assorted vegetables on it.\nA decorative container with mini roses is sitting on a pedestal. \nA large  white, blue, and red clock shaped like a cup.\nMany people are posing for the camera outside. \nA girl standing in a field, wearing a red sweater and a pair of blue jeans\nRed train engine holding other cars to it. \nA couple of zebras are standing in a field\nA man smiles maniacly while putting a dog into an oven.\nA plumbing sign hangs on a pole next to a road.\nA woman playing frisbee in a park \nTwo children who are on wake boards in the ocean.\ntwo people are walking past a fire hydrant spraying water\nA person dressed up as a chef cooking.\nTwo piles of trunks sitting next to each other.\nA umbrella sitting over lawn chairs on a beach.\nA skateboarder flips his skateboard as he flies through the air.\na big line of motorcycle that is parked on a concrete \nA woman stands next to a kite in a sunny park.\nA large animal laying on top of a dirt and grass ground.\nA pair of glasses, a pocket watch and two books.\nsome people playing in a park with a kite\nA person with a football running with another person behind them.\nA rumbled bed sits empty as sun shines in the adjacent window. \nA zebra is looking at the camera in a field.\nA refrigerator sitting on the inside of a large stone mountain.\na messy bathroom in a fast food restaurant \nA woman is sitting on a bench in front of the water.\nA man hitting a tennis ball with a racquet.\nA man walking while holding an umbrella on a wet sidewalk.\nGirl dressed in a scouting uniform standing near a fence with her foot on a small cannon.\nA very large tower like structure with two clocks on it.\nThe woman playing on the clay court has hit a tennis ball. \nTwo rams stand in the snow up to their ankles\na little kid is brushing his teeth and smiling\nCamp with make shift outdoor kitchen room \nA living room with large windows facing the forest.\nA white toilet in a bathroom next to a trash can.;\nA woman with a parasol stands in front of stage.\nA small bird sitting on a chair by a table.\nA bus is parked on the side of an empty street.\nTwo open laptops on a desk pointing in different directions. \nKids are skateboarding at a skate park and one them has fallen down.\nA small, black train is on its tracks by a fence.\nA mess sits on the floor of an otherwise clean kitchen.\nA man in a tiny boat next to many boats with the Canadian flag.\nSoccer players during match play in city environment.\nA man and dog on a sit upon kayak getting off at a dock\nA red truck sitting in a parking lot with the hood up.\nA woman riding skis across a snow covered slope.\nThe pizza is prepared and ready to be eaten\nA spotted dog is chasing another dog outside\nA person is standing in front of a dog.\nA dog with a stuffed animal sitting on a bed.\nA group of giraffe Standing up against a dirt wall in front of a crowd of children.\nA mother elephant bumping her trunk against her baby's forehead.\nA dog sitting in the front seat of a truck.\nTwo giraffes standing in a field together in front of rocks and trees. \nA vintage teddy bear cuddles in the midst of pillows.\nTwo men in room playing a game with Nintendo Wii controllers.\nSome people out in the water with a sail in the sky.\nA quiet highway with a street sign up ahead.\nThe woman is riding her bike pass the sign with the zebra.\nA cute giraffe sitting on the ground in a zoo exhibit. \nthere is a man and a woman sitting at a table smiling\na lady that has a umbrella in her hand\nA woman wearing an Army t-shirt hits a tennis ball\nvarious flowers and vines sitting on top of a ceramic, circular object\nPeople sitting in a room and watching a small television.\nA baseball team playing a baseball game in front of a crowd.\nA man is lighting something at the bar table next to his phone. \nA man flying an airplane kite in the sky.\nA child is in front of a birthday cake with candles.\nA pizza with pepperonis, mushrooms, tomatoes and other various toppings.\nA close shot of a toilet with the seat up and some toilet paper. \nan image of a couple playing video game\nA red, white and green Amtrak train stopped at a station. \nTwo people sit together in a restaurant at a wooden table.\na table that has a vase with a flower in it\nA train traveling between two very large rocky mountains.\nA woman leaning on a building talking on her cell phone \nThe hot dog is on a plate with a pickle next to it.\nA desk that has three computers and a printer on it.\nA person that is laying on a surfboard in the water.\nAssorted colored plastic flowers in a white vase.\nA herd of zebras in the wild near grassy terrain.\nThe father and daughter are under an umbrella on the beach.\nA black wii controller  showing from bottom up.\nThree large vases with flowers in front of a dining area.\nA surfer surfing on the surfboard with an oar in the ocean. \nA brown bear sitting on a bunch of fallen logs\na yellow train parked on the track next to a platform\nA woman standing in front of window next to a bug and a stop sign.\npot like models on a table well molded\nA woman seated at a table is holding a glass of wine.\nA banana tree with bananas hanging from its branches\na picture frame a cup with flowers resting on the desk\nA guy does a skate board trick while people watch. \nA batter for the Boston Red Sox walking on the field.\nA group of people work in a kitchen together.\na snowboarded catching air jumping off a slope \nClose up of a street pole with a stop sign with graffiti under a one way sign under two street signs with low buildings, telephone poles and wires behind and a blue sky with clouds.\nA person stands in the snow holding a snowboard.\nA red stop sign sitting on the side of a road.\nCat catty sitting on a suitcase with a closed kennel against the wall.\nA brightly lit restaurant on the side of the road at night.\nSomeone in a room taking a picture with phone out a barred window.\nA woman is holding an open red umbrella over her head.\nA truck traveling down a highway road filled with oranges.\nA pile of books scattered across a naked mattress.\nA plate of food and some cups of drink on a table.\nA public clock with ornate art deco figurines of women supporting it\nA man that is on skis in the snow.\nA young man looks delighted with his shiny snowboard.\na cat sleeping on the floor with a little toy\nA group of people standing on top of surfboards next to the ocean.\nA road sign on top of a stop sign \nA plate of pasta, mushrooms, broccoli. and cheese.\nA city block with people, cars, buses and a street vendor. \nA tablecloth has children's writing on it and a pizza.\nMen playing with a frisbee in a dry field \nAn baby elephant is nudged by an older elephant in front of a stilt house. \nAn umbrella with a cat sitting underneath it.\nThree surfers and one swimmer watching a beginner surf\na black and white photo of a fire hydrant a curb and fence\nAn old fire hydrant in the middle of the woods.\nA bird is wading in the shallow water.\nA made bed with mosquito netting above it.\nA player that is getting ready to go up to bat at a baseball game.\nA sign in front of a brick wall that says accident prone zone\nCat sat outside on a small folding wooden chair\na couple of sheep are in a grassy field\nA bathroom with a toilet and standup shower.\nTwo teddy bears with balloons on a chair \nFresh carrots on cabbage leaves on a formal place setting\na small wood table with a small computer on it \nA woman eating a plate of food at a table.\nTwo people in a bedroom holding wii remotes.\nA group of people sit on the beach behind two surfboards.\nA herd of zebras, ibex, and wilder beasts on the planes.\nA meal, coffee, pictures and a notebook on a table.\nA picture of various roadsigns and a crosswalk signal.\nA man is standing in a train in a train station.\na couple of cellphones are laying out together\nA person holding a sandwich made out of pretzels, cheese, and deli sliced meat.\nA man and woman at a table with several drinks.\na zebra with his mouth open in a field.\nAn elephant is facing forward with zebras in the background. \nA white plate topped with meat veggies and rice with sauce.\nA man is taking his picture in a mirror.\nA kitchen has white cabinets and a white microwave.\nA toaster is decorated with kitchen utensils to have a sad expression. \nEmpty aqua bathroom with toilet, sink, mirror, and outside window.\na little girl is holding on to a hair brush\nsome glazed donuts are sitting on a white counter\nA train carrying army trucks with men standing on it.\nThe two dogs are laying on the bed.\na close up of a painted parking meter on a street\nA colorful market booth sells bananas to a customer.\nSomeone patting the head of a large stuffed teddy bear\nHang gliders fly over the water on a choppy day.\nPEOPLE OBSERVING AND CLICKING PICTURES AT AN ANTIQUE PLACE.\nA pizza with toppings sitting on a tray.\nThe center of a plant with lots of leaves.\nAn old man holding a plaque next to a motorcycle.\nA cat that is sitting in a basket under a bench.\nA cat sits in a blue patterned folding chair outdoors.\nthere are two elephants that are walking on the road\nOld hot rods are sitting in a grass lot.\nA man brushing his teeth, taking a picture of himself.\nCat looking out car window from car seat.\nA double decker bus that is driving on the road.\nA woman is sitting on an old wooden bench.\nTwo women playing a game with a Nintendo Wii controller.\nA man on a motorcycle in heavy traffic \nA dog jumping through the air into a pool.\nA group of people riding snow boards on top of a slope.\nA skateboarder doing tricks on the edge of a wall.\nFour way stop sign at street intersection and two street signs above\nA cat sitting in a suitcase on a bed \na man on a skateboard in the air coming on to a ramp\nA view of a man wearing a casual shirt and tie.\nA commercial international airline jet on a runway strip.\nTwo small birds are resting on a tree branch.\ntwo people standing on a field with a kite flying above \nThere are several kites flying over a crowd of people.\nA small bird is perched on a branch in a tree.\nA group of baseball players that are standing in the field.\nA man standing on top of a tennis court.\nBirthday cake for a friend that is ill\nA group of giraffe walking across a dirt field.\nA truck driving down a street next to a forest.\na large air plane flying in the air\nan image of people posing for the camera\nA boy smiles while two little dogs are inside of two tennis shoes.\nA young man is taking a \"selfie\" of himself. \nA keyboard and some ear phones are on a table.\nA large group of people eating under a tent.\nGroup of people riding on the back of large elephant. \nLong rows of white urinals sitting on a wall in a bathroom. \nA toilet with an apparatus to the side of it.\nWorking elephants in a village meander along a river bank. \nA plane equipped for water landing sits on a runway.\nThree giraffe's laying in a grassy open area with trees. \nA group of horse back riders on a wooded trail.\nA passenger jet airplane flying in a mostly cloudy sky.\nA restaurant with patrons in the outdoor eating area.\nA musician with a smile on his face prepares to play the violin.\nA cheese omelet with toast on a plate.\nA train car with purple and grey graffiti covering windows\nA meat sandwich sitting on top of a white plate.\na bathroom with a mirror and a sink in it\nA blue car passing a sign that reads \"crepes ice cream gelato.\"\nSeveral adults engaged in arts and crafts with children.\nA set of bright yellow luggage with wheels.\nA boy stares at a pizza with a birthday candle in it.\nBoats in a river on a foggy day. \nA bathroom with three stalls and three different styles of urinals.\nA motorcycle and couple of bicycles sitting on rugs in a store.\nA plate of lamb chop, new potatoes, and steamed carrot slices.\nA long sheet of pizza sitting on top of a table.\nLarge orange raft sits on boat deck attached to crane.\nA bench under water in a park that has been flooded \nA boy standing in front of a tee ball tee with a bat.\nAs the sun sets, a boy and his father take their surfboard out of the water.\na big clock a rod iron roof and a round window\na train on railroad tracks at a station\nTwo women are skiing down a small hill.\nA stop sign on the corner with garbage cans\nFour donuts in a box with different toppings on them.\nA very cute small girl by a very big pizza.\nA green bird sitting on top of a desk chair.\nAn older man walking away holding a kite\nA clock in the outdoors showing ten fifty. \nA cat laying on top of a blanket near a wall.\na dog with a plate of food on the ground\nA tennis player preparing to hit the ball.\nColorful passenger trains make their way on parallel tracks.\nSheep in a field by the fence on a clear day.\nsome oranges are stacked up in a bowl\nA puppy sitting on the ground in a bathroom\na man swinging a tennis racket on a tennis court\nA  pair of people sitting on a motorcycle, in the grass.\nan empty street and signals that are red\nA wooden fishing boat in the middle of a grass field with snow capped mountains in the background.\nA pair of men dressed in civil war outfits riding horses.\nPeople with luggage are at the train station.\nTwo people playing a video game in their living room.\nA very nice looking living and dining room fully furnished.\nA man on skis going over a small jump.\nAn air mattress, plastic chair and bike decorate this room.\nSeveral birds perched on a giraffe's neck eating bugs.\nA group of people standing in the sand with a kite.\nA boy on a skateboard hovers over a half pipe.\nA long train travels past some trees along the railroad tracks\nTwo men dressed in business attire shaking hands.\nA man goes through the water on a parasail.  \nA man laying in bed with w child reading him a story\nTwo blankets have been folded on a large bed.\nPeople looking at a large group of sheep in a fence in the middle of a city.\nA plate of spaghetti with tomato sauce and a garnish of broccoli.\nhotel room with two beds and a large window\na train that is on a old train track\nA sailboat in the water, near a rocky island with a lighthouse on it.\nMany bunches of fresh locally grown ripe bananas.\nA bicycle is on the street in front of a window.\nA batter up to bat at a baseball game.\nA pizza sitting on top of a plate covered in cheese and tomatoes.\nA group of men play indoor soccer together. \na black and white photo of children siting posing for a photo\nA blue teddy bear surrounded by other stuffed animals.\nAn apple computer with a keyboard and mouse underneath it.\nA glass vase full of red flowers and greenery.\nA man and women pose at a wedding.\nThe cardinal on the tail of a plane on the tarmac.\nTwo brown horses standing next to each other in a field.\nThree buses pulled in front of a bus station loading passengers.\na person standing next to a snow board with mountains in the background\nFour people are smiling and holding up smart phone devices.\na man on a skateboard jumping over a stairway\na kid is sitting in front of a laptop\nA man and a boy standing next to a tall giraffe.\nA smiling baby is laying in a suitcase.\na metal pole with a single sign is next to a wood pole with many signs\na yellow and blue fire hydrogen that is next to a road\nA child tries to feed an adult a piece of food\na close up of a stuffed animal near a book\nA black and white photo of a computer keyboard, flash drive, and mouse on a marble tabletop.\nA woman holds onto a teddy bear while on a plane. \nA computer monitor sitting on top of a wooden table.\nA kitchen that has carpeted floors and wooden cabinets.\nA sign showing the way to Atlas Road.\nA surfboard on top of a beaten car near the ocean\nA group of people sitting next to each other in front of a TV.\na cat that is parked on a purple car\nA plate with dinner items on it, on a white table cloth.\na few zebra are out in the open eating some hay\nA man is going down the water on a paddle board.\nThe snow is very crowded with snow skiers.\nA man posing behind a plate of food.\nA stop sign leaning over in melting snow.\nMan and woman sitting on a wooden park bench together. \nThe twin boys are looking at the black bear.\na laptop with a mouse sitting on a towel \nA white dog is sitting on the back of a couch.\na furry brown hound sits on the snow in front of some garden patio furniture\nA herd of zebra standing next to each other against a stone wall.\nBathroom sink with wooden cabinet and granite top.\nA red stoplight with a street in the background.\nA smiling man with a moustache is handed a plate by another man standing at a table with holiday decorations..\nA man riding a bike down a street.\nA little girl that is hitting a baseball.\nA large group of people take a tour of a cargo plane.\nTwo men in blazers and fedoras with a moped in the background.\nA woman with a black purse and a bath tub.\nA woman taking a bite of a doughnut in a restaurant.\nA group of steer with large horns lay in a field.\nA park and walkway lined with benches and bushes.\nIt looks like this student is well-supplied with caffeine for an all-night cramming session.\nAn empty bathroom with a sink, toilet, scale and brown towel \nWoman throwing a rope towards horse at rodeo\nA clean kitchen with warm sun light streaming in\nA produce vendor and a customer on a sidewalk.\nA group of people crossing a street next to a stop sign.\na city bus is parked along a deserted side street\nsome people standing on a tennis court holding tennis racketts\na snowboard instructor teaching students how to snowboard \nA white toilet sitting under a window in a bathroom.\na white plate with a variety of meat and vegetables\nA pile of stuff on the floor next to a bed\nA orange before and after it was cut\nA uncooked whole chicken in a white microwave.\nTwo kids wearing skis and helmets in the snow.\na train moving on the rail near a forest\nA woman walking with a pan in her hands with a whole pizza on it. \nA table full of many different types of food.\nA jet airliner with landing gear down and flaps extended.\nA man with a tie has his feet bent up in the air.  \nA man is in front of an open oven door.\nA muddy motorcycle is parked near other vehicles in a field.\nA slice of pizza on a white plate.\nOld cooking implements on wooden shelves in a white room.\nPEOPLE CELEBRATING WITH CHOCOLATE CAKE AND WINE \nA purple rag laying in a toilet bowl.\nLilacs in a blue watering can vase sitting outdoors on a ledge.\nA colorful bird sits on a tree limb.\na man standin on a sidewalk on a hill\nA train car's open door exposes a sink and toilet room. \nan open read with trees lining each side of the road\nA plant in a antique vase outside. \nCenturies old tower with a clock and topped with a cross.\nthe doll is a table with two stuffed dogs\nTwo people on a long rowboat in a river or lake.\na plate with three kinds of food on it\nA street sign on a pole on a road.\na woman standing in a kitchen cooks some food\nThree people on the beach standing with surfboards.\nA car driving down a busy city street at night.\nA golden elephant working as signage on a building facade.\nA group of red and blue tourist buses going over a bridge.\nSome boats parked in the water at a dock\na dog running with a Frisbee in its mouth\na surfer riding the wave at the beach\nmany people at tables with drinks and food \nA female tennis player is positioning herself for her next move.\nThe tray has a sandwich and two bowls near a beverage. \nhere is a clock on the window that has too late written on it \nGiraffe standing in the shade of a tall covering \na pole that has a bunch of street signs on it\nA baseball game is being played before a crowd.\nA group of zebras walk along the sand.\nA horse has a cover over its mouth\nPhoto taking in a building looking at a staircase.\nThis studio apartment has a twin size bed by the wall.\nA man cutting a cake with his bride.\nA close up of a black and white teddy bear sitting on a bench.\na lady standing in front of potted plants.\nPassengers wait at the platform as a passenger train approaches.\na man cutting a slice of cake with the knife\nFive kids playing with frisbees on a sunny day.\nSeveral birds stand and lay near the water.\nA blue colored passenger bus that is parked on road next to a building.\nA woman with a red tutu standing in the middle of a city street. \nA man with his focus looking up at the camera.\nA herd of white sheep standing on a green hillside.\nA road is covered with snow with some tire tracks.\nThere are tooth brush and gum like candies.\nA cat sitting at the edge of a couch looking ahead.\nA computer, lamp, and books sit on a desk.\nA woman that is standing in the water next to a surfboard.\nA bathroom with tall ceilings and an open window on the top.\na big train sits parked with graffiti on it \nA adult holding a child biting into a remote.\nTwo people look on as two others play a video game.\nProfessional baseball player sliding in to the base\nSeveral dogs on a yellow school bus with a stop sign below the window.\nA PICTURE OF BAR B QUE SITTING ON A TABLE \nA woman and a dog tussle over a frisbee.\nA zebra and its foal eating hay from a basket.\na white purse sits on a bed under a phone, camera and flask\nA YOUNG BLACK COW IS IN SOME SORT OF OUTDOOR INCLOSURE\nA train parked in front of a train station.\nAn uneaten pizza pie cut into 4 quarters\nA herd of horses gathered at the top of a hill.\nBreakfast is complete with a large waffle topped with bananas.\nA remote and cup held by a woman with glasses\na group of elephants near a body of water \nA couple of women sitting next to each other.\nA photo of a reflection of a group of people lounging outside.\nA man rides his wake board while paragliding\nYoung men riding skate boards along a marked path on the pavement.\nblack and white photo of a scooter carrying numerous bikes\nA man standing in the ocean filled with waves.\nA bedroom in the loft of a wooden cabin\na black and white dog a bicycle and a person and buildings\nTwo people having a meal at a diner.\nA person in a deserted subway station waits for the train to pass. \na white and blue jet is at the airport\n3 surf boarders enjoying themselves in the ocean.\nWoman adjusting man's tie in occupied room with others.\nA work desk with a silver laptop propped up on top of the desk.\nA woman preparing to hit a tennis ball while a man watches.\na person is holding up a small child\nBarber cutting a child's hair in a barber shop.\ntwo female sitting at a table across from eachother eating pizza\nA man playing with a brown dog on top of a green field.\ntwo small kids sitting at a table and on a lap top\na view into a kitchen with  counter tops and wooden floors\nThere are horses pulling a man and a cart.\nTwo women playing a video game in a living room.\nA black and white cat sleeps next to a stuffed bear.\nThe baseball player is standing in the outfield. \nAn air plane going down the runway on a clear day.\nA whole pizza pie with many different toppings sitting on a pizza stand.\nA facade to the front on an old church.\nA meal at a restaurant of a salad, a toasted sandwich and a pickle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T13:27:21.001411Z","iopub.execute_input":"2025-02-02T13:27:21.001756Z","iopub.status.idle":"2025-02-02T13:27:21.032463Z","shell.execute_reply.started":"2025-02-02T13:27:21.001729Z","shell.execute_reply":"2025-02-02T13:27:21.031482Z"}},"outputs":[{"name":"stdout","text":"Writing for1k.txt\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!python txt2img.py --from-file /kaggle/working/for1k.txt --ckpt /kaggle/input/stable-sig/stable_signature-main/v2-1_512-ema-pruned.ckpt --ldm_decoder_ckpt /kaggle/input/checkpointformine/checkpointnew_vgg.pth --config /kaggle/input/stable-sig/stable_signature-main/v2-inference.yaml  --H 512 --W 512 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:44:08.656382Z","iopub.execute_input":"2025-02-11T06:44:08.656647Z","iopub.status.idle":"2025-02-11T06:44:08.872701Z","shell.execute_reply.started":"2025-02-11T06:44:08.656622Z","shell.execute_reply":"2025-02-11T06:44:08.871660Z"}},"outputs":[{"name":"stdout","text":"python3: can't open file '/kaggle/working/txt2img.py': [Errno 2] No such file or directory\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%writefile txt2img.py\nimport argparse, os\nimport cv2\nimport sys\nsys.path.append('src')\nimport torch\nimport numpy as np\nfrom omegaconf import OmegaConf\nfrom PIL import Image\nfrom tqdm import tqdm, trange\nfrom itertools import islice\nfrom einops import rearrange\nfrom torchvision.utils import make_grid\nfrom pytorch_lightning import seed_everything\nfrom torch import autocast\nfrom contextlib import nullcontext\n# from imwatermark import WatermarkEncoder\nfrom ldm.util import instantiate_from_config\nfrom ldm.models.diffusion.ddim import DDIMSampler\nfrom ldm.models.diffusion.plms import PLMSSampler\nfrom ldm.models.diffusion.dpm_solver import DPMSolverSampler\n\ntorch.set_grad_enabled(False)\n\ndef chunk(it, size):\n    it = iter(it)\n    return iter(lambda: tuple(islice(it, size)), ())\n\ndef insert_watermark_in_latents(samples, watermark_latent, alpha=0.05):\n    \"\"\"\n    Inserts an imperceptible watermark into the latent representation.\n\n    Args:\n        samples (torch.Tensor): The latent representation of the image (B, C, H, W).\n        watermark_latent (DiagonalGaussianDistribution): The latent representation of the watermark.\n        alpha (float): Scaling factor for the watermark (default: 0.1, adjust as needed).\n\n    Returns:\n        torch.Tensor: The modified latent representation with the imperceptible watermark.\n    \"\"\"\n    # Ensure watermark_latent is sampled correctly\n    if hasattr(watermark_latent, 'sample'):\n        watermark_latent_tensor = watermark_latent.sample()  # Call sample as a method\n    else:\n        raise TypeError(f\"Expected a DiagonalGaussianDistribution, got {type(watermark_latent)}\")\n\n    # Get the shape of the watermark latent tensor\n    wm_h, wm_w = watermark_latent_tensor.shape[2], watermark_latent_tensor.shape[3]\n\n    # Compute the center of the image latent tensor\n    center_h, center_w = samples.shape[2] // 2, samples.shape[3] // 2\n\n    # Determine the position to insert the watermark\n    start_h, start_w = center_h - wm_h // 2, center_w - wm_w // 2\n\n    # Blend the watermark latents into the image latents\n    samples[:, :, start_h:start_h+wm_h, start_w:start_w+wm_w] += alpha * watermark_latent_tensor\n\n    return samples\n\n\ndef load_model_from_config(config, ckpt, device=torch.device(\"cuda\"), verbose=False):\n    print(f\"Loading model from {ckpt}\")\n    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n    if \"global_step\" in pl_sd:\n        print(f\"Global Step: {pl_sd['global_step']}\")\n    sd = pl_sd[\"state_dict\"]\n    model = instantiate_from_config(config.model)\n    m, u = model.load_state_dict(sd, strict=False)\n    if len(m) > 0 and verbose:\n        print(\"missing keys:\")\n        print(m)\n    if len(u) > 0 and verbose:\n        print(\"unexpected keys:\")\n        print(u)\n\n    if device == torch.device(\"cuda\"):\n        model.cuda()\n    elif device == torch.device(\"cpu\"):\n        model.cpu()\n        model.cond_stage_model.device = \"cpu\"\n    else:\n        raise ValueError(f\"Incorrect device name. Received: {device}\")\n    model.eval()\n    return model\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--prompt\",\n        type=str,\n        nargs=\"?\",\n        default=\"a professional photograph of an astronaut riding a triceratops\",\n        help=\"the prompt to render\"\n    )\n    parser.add_argument(\n        \"--outdir\",\n        type=str,\n        nargs=\"?\",\n        help=\"dir to write results to\",\n        default=\"outputs/txt2img-samples\"\n    )\n    parser.add_argument(\n        \"--steps\",\n        type=int,\n        default=50,\n        help=\"number of ddim sampling steps\",\n    )\n    parser.add_argument(\n        \"--plms\",\n        action='store_true',\n        help=\"use plms sampling\",\n    )\n    parser.add_argument(\n        \"--dpm\",\n        action='store_true',\n        help=\"use DPM (2) sampler\",\n    )\n    parser.add_argument(\n        \"--fixed_code\",\n        action='store_true',\n        help=\"if enabled, uses the same starting code across all samples \",\n    )\n    parser.add_argument(\n        \"--ddim_eta\",\n        type=float,\n        default=0.0,\n        help=\"ddim eta (eta=0.0 corresponds to deterministic sampling\",\n    )\n    parser.add_argument(\n        \"--n_iter\",\n        type=int,\n        default=1,\n        help=\"sample this often\",\n    )\n    parser.add_argument(\n        \"--H\",\n        type=int,\n        default=512,\n        help=\"image height, in pixel space\",\n    )\n    parser.add_argument(\n        \"--W\",\n        type=int,\n        default=512,\n        help=\"image width, in pixel space\",\n    )\n    parser.add_argument(\n        \"--C\",\n        type=int,\n        default=4,\n        help=\"latent channels\",\n    )\n    parser.add_argument(\n        \"--f\",\n        type=int,\n        default=8,\n        help=\"downsampling factor, most often 8 or 16\",\n    )\n    parser.add_argument(\n        \"--n_samples\",\n        type=int,\n        default=1,\n        help=\"how many samples to produce for each given prompt. A.k.a batch size\",\n    )\n    parser.add_argument(\n        \"--n_rows\",\n        type=int,\n        default=0,\n        help=\"rows in the grid (default: n_samples)\",\n    )\n    parser.add_argument(\n        \"--ldm_decoder_ckpt\",\n        type=str,\n        default=None,\n        # default=\"/kaggle/input/forstatistics/checkpoint_009.pth\",\n    )\n    parser.add_argument(\n        \"--scale\",\n        type=float,\n        default=3.0,\n        help=\"unconditional guidance scale: eps = eps(x, empty) + scale * (eps(x, cond) - eps(x, empty))\",\n    )\n    parser.add_argument(\n        \"--from-file\",\n        type=str,\n        help=\"if specified, load prompts from this file, separated by newlines\",\n    )\n    parser.add_argument(\n        \"--config\",\n        type=str,\n        default=\"configs/stable-diffusion/v2-inference.yaml\",\n        help=\"path to config which constructs model\",\n    )\n    parser.add_argument(\n        \"--ckpt\",\n        type=str,\n        help=\"path to checkpoint of model\",\n    )\n    parser.add_argument(\n        \"--seed\",\n        type=int,\n        default=42,\n        help=\"the seed (for reproducible sampling)\",\n    )\n    parser.add_argument(\n        \"--precision\",\n        type=str,\n        help=\"evaluate at this precision\",\n        choices=[\"full\", \"autocast\"],\n        default=\"autocast\"\n    )\n    parser.add_argument(\n        \"--repeat\",\n        type=int,\n        default=1,\n        help=\"repeat each prompt in file this often\",\n    )\n    parser.add_argument(\n        \"--device\",\n        type=str,\n        help=\"Device on which Stable Diffusion will be run\",\n        choices=[\"cpu\", \"cuda\"],\n        default=\"cuda\"\n    )\n    parser.add_argument(\n        \"--torchscript\",\n        action='store_true',\n        help=\"Use TorchScript\",\n    )\n    parser.add_argument(\n        \"--ipex\",\n        action='store_true',\n        help=\"Use Intel® Extension for PyTorch*\",\n    )\n    # parser.add_argument(\n    #     \"--bf16\",\n    #     action='store_true',\n    #     help=\"Use bfloat16\",\n    # )\n    opt = parser.parse_args()\n    return opt\n\ndef main(opt):\n    seed_everything(opt.seed)\n\n    config = OmegaConf.load(f\"{opt.config}\")\n    device = torch.device(\"cuda\") if opt.device == \"cuda\" else torch.device(\"cpu\")\n    model = load_model_from_config(config, f\"{opt.ckpt}\", device)\n    # Parameter None for clutil sweep\n    print(f'reload decoder weights {opt.ldm_decoder_ckpt}...')\n    if opt.ldm_decoder_ckpt is not None and opt.ldm_decoder_ckpt.lower() == \"none\":\n        opt.ldm_decoder_ckpt = None\n    if opt.ldm_decoder_ckpt is not None:\n        state_dict = torch.load(opt.ldm_decoder_ckpt)['ldm_decoder']\n        # state_dict = torch.load(opt.ldm_decoder_ckpt)['state_dict']\n        # state_dict = {k.replace('first_stage_model.', ''): v for k, v in state_dict.items() if 'decoder' in k or 'post_quant_conv' in k}\n        msg = model.first_stage_model.load_state_dict(state_dict, strict=False)\n        model.eval()\n        print(msg)\n\n    if opt.plms:\n        sampler = PLMSSampler(model, device=device)\n    elif opt.dpm:\n        sampler = DPMSolverSampler(model, device=device)\n    else:\n        sampler = DDIMSampler(model, device=device)\n\n    os.makedirs(opt.outdir, exist_ok=True)\n    outpath = opt.outdir\n    batch_size = opt.n_samples\n    n_rows = opt.n_rows if opt.n_rows > 0 else batch_size\n    if not opt.from_file:\n        prompt = opt.prompt\n        assert prompt is not None\n        data = [batch_size * [prompt]]\n    else:\n        print(f\"reading prompts from {opt.from_file}\")\n        with open(opt.from_file, \"r\") as f:\n            data = f.read().splitlines()\n            data = [p for p in data for i in range(opt.repeat)]\n            data = list(chunk(data, batch_size))\n\n    sample_path = os.path.join(outpath, \"samplesnonwater50k\")\n    os.makedirs(sample_path, exist_ok=True)\n    sample_count = 0\n    base_count = len(os.listdir(sample_path))\n    grid_count = len(os.listdir(outpath)) - 1\n\n    start_code = None\n    if opt.fixed_code:\n        start_code = torch.randn([opt.n_samples, opt.C, opt.H // opt.f, opt.W // opt.f], device=device)\n        \n    if opt.torchscript or opt.ipex:\n        transformer = model.cond_stage_model.model\n        unet = model.model.diffusion_model\n        decoder = model.first_stage_model.decoder\n        additional_context = torch.cpu.amp.autocast() if opt.bf16 else nullcontext()\n        shape = [opt.C, opt.H // opt.f, opt.W // opt.f]\n\n        if opt.bf16 and not opt.torchscript and not opt.ipex:\n            raise ValueError('Bfloat16 is supported only for torchscript+ipex')\n        if opt.bf16 and unet.dtype != torch.bfloat16:\n            raise ValueError(\"Use configs/stable-diffusion/intel/ configs with bf16 enabled if \" +\n                             \"you'd like to use bfloat16 with CPU.\")\n        if unet.dtype == torch.float16 and device == torch.device(\"cpu\"):\n            raise ValueError(\"Use configs/stable-diffusion/intel/ configs for your model if you'd like to run it on CPU.\")\n\n        if opt.ipex:\n            import intel_extension_for_pytorch as ipex\n            bf16_dtype = torch.bfloat16 if opt.bf16 else None\n            transformer = transformer.to(memory_format=torch.channels_last)\n            transformer = ipex.optimize(transformer, level=\"O1\", inplace=True)\n\n            unet = unet.to(memory_format=torch.channels_last)\n            unet = ipex.optimize(unet, level=\"O1\", auto_kernel_selection=True, inplace=True, dtype=bf16_dtype)\n\n            decoder = decoder.to(memory_format=torch.channels_last)\n            decoder = ipex.optimize(decoder, level=\"O1\", auto_kernel_selection=True, inplace=True, dtype=bf16_dtype)\n\n        if opt.torchscript:\n            with torch.no_grad(), additional_context:\n                # get UNET scripted\n                if unet.use_checkpoint:\n                    raise ValueError(\"Gradient checkpoint won't work with tracing. \" +\n                    \"Use configs/stable-diffusion/intel/ configs for your model or disable checkpoint in your config.\")\n\n                img_in = torch.ones(2, 4, 96, 96, dtype=torch.float32)\n                t_in = torch.ones(2, dtype=torch.int64)\n                context = torch.ones(2, 77, 1024, dtype=torch.float32)\n                scripted_unet = torch.jit.trace(unet, (img_in, t_in, context))\n                scripted_unet = torch.jit.optimize_for_inference(scripted_unet)\n                print(type(scripted_unet))\n                model.model.scripted_diffusion_model = scripted_unet\n\n                # get Decoder for first stage model scripted\n                samples_ddim = torch.ones(1, 4, 96, 96, dtype=torch.float32)\n                scripted_decoder = torch.jit.trace(decoder, (samples_ddim))\n                scripted_decoder = torch.jit.optimize_for_inference(scripted_decoder)\n                print(type(scripted_decoder))\n                model.first_stage_model.decoder = scripted_decoder\n\n        prompts = data[0]\n        print(\"Running a forward pass to initialize optimizations\")\n        uc = None\n        if opt.scale != 1.0:\n            uc = model.get_learned_conditioning(batch_size * [\"\"])\n        if isinstance(prompts, tuple):\n            prompts = list(prompts)\n\n        with torch.no_grad(), additional_context:\n            for _ in range(3):\n                c = model.get_learned_conditioning(prompts)\n            samples_ddim, _ = sampler.sample(S=5,\n                                             conditioning=c,\n                                             batch_size=batch_size,\n                                             shape=shape,\n                                             verbose=False,\n                                             unconditional_guidance_scale=opt.scale,\n                                             unconditional_conditioning=uc,\n                                             eta=opt.ddim_eta,\n                                             x_T=start_code)\n            print(\"Running a forward pass for decoder\")\n            for _ in range(3):\n                x_samples_ddim = model.decode_first_stage(samples_ddim)\n\n    precision_scope = autocast if opt.precision==\"autocast\" or opt.bf16 else nullcontext\n    with torch.no_grad(), \\\n        precision_scope(opt.device), \\\n        model.ema_scope():\n            all_samples = list()\n            for n in trange(opt.n_iter, desc=\"Sampling\"):\n                for prompts in tqdm(data, desc=\"data\"):\n                    uc = None\n                    if opt.scale != 1.0:\n                        uc = model.get_learned_conditioning(batch_size * [\"\"])\n                    if isinstance(prompts, tuple):\n                        prompts = list(prompts)\n                    c = model.get_learned_conditioning(prompts)\n                    shape = [opt.C, opt.H // opt.f, opt.W // opt.f]\n                    samples, _ = sampler.sample(S=opt.steps,\n                                                     conditioning=c,\n                                                     batch_size=opt.n_samples,\n                                                     shape=shape,\n                                                     verbose=False,\n                                                     unconditional_guidance_scale=opt.scale,\n                                                     unconditional_conditioning=uc,\n                                                     eta=opt.ddim_eta,\n                                                     x_T=start_code)\n                    watermark_image = Image.open('/kaggle/input/mnistasjpg/testSet/testSet/img_100.jpg').convert('RGB')  # assuming RGB for color watermark\n                    watermark_image = watermark_image.resize((32, 32), Image.Resampling.LANCZOS)\n                    watermark_tensor = torch.tensor(np.array(watermark_image), dtype=torch.float32)  # Normalize to [0, 1]\n                    watermark_tensor = watermark_tensor.permute(2, 0, 1).unsqueeze(0)  # Add batch dim and change channel order to CxHxW\n\n            # Pass the watermark through the encoder to get the latent representation\n                    watermark_latent = model.encode_first_stage(watermark_tensor.to(opt.device))  # Assuming an encoder method exists\n            # Insert the watermark latent into the samples\n                    modified_latents = insert_watermark_in_latents(samples, watermark_latent)\n                    # x_samples = model.decode_first_stage(samples)\n                    if opt.ldm_decoder_ckpt is not None and opt.ldm_decoder_ckpt.lower() == \"none\":\n                        x_samples = model.decode_first_stage(samples)\n                    else:\n                        x_samples = model.decode_first_stage(modified_latents)\n                    x_samples = torch.clamp((x_samples + 1.0) / 2.0, min=0.0, max=1.0)\n\n                    for x_sample in x_samples:\n                        x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')\n                        img = Image.fromarray(x_sample.astype(np.uint8))\n                        # img = put_watermark(img, wm_encoder)\n                        img.save(os.path.join(sample_path, f\"{base_count:05}.png\"))\n                        base_count += 1\n                        sample_count += 1\n\n                    all_samples.append(x_samples)\n\n            # # additionally, save as grid\n            # grid = torch.stack(all_samples, 0)\n            # grid = rearrange(grid, 'n b c h w -> (n b) c h w')\n            # grid = make_grid(grid, nrow=n_rows)\n\n            # # to image\n            # grid = 255. * rearrange(grid, 'c h w -> h w c').cpu().numpy()\n            # grid = Image.fromarray(grid.astype(np.uint8))\n            # # grid = put_watermark(grid, wm_encoder)\n            # grid.save(os.path.join(outpath, f'grid-{grid_count:04}.png'))\n            # grid_count += 1\n\n    print(f\"Your samples are ready and waiting for you here: \\n{outpath} \\n\"\n          f\" \\nEnjoy.\")\n\nif __name__ == \"__main__\":\n    opt = parse_args()\n    main(opt)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python txt2img.py --from-file /kaggle/working/for1k.txt --ckpt /kaggle/input/stable-sig/stable_signature-main/v2-1_512-ema-pruned.ckpt --ldm_decoder_ckpt none --config /kaggle/input/stable-sig/stable_signature-main/v2-inference.yaml  --H 512 --W 512 ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r first1kk.zip /kaggle/working/outputs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}